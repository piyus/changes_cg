diff -ur native/benchspec/CPU/502.gcc_r/src/c-common.c spec/benchspec/CPU/502.gcc_r/src/c-common.c
--- native/benchspec/CPU/502.gcc_r/src/c-common.c	2015-10-17 01:58:29.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/c-common.c	2021-04-15 09:31:21.215884329 +0530
@@ -5292,6 +5292,8 @@
 int
 case_compare (splay_tree_key k1, splay_tree_key k2)
 {
+	k1 &= 0xffffffffffffULL;
+	k2 &= 0xffffffffffffULL;
   /* Consider a NULL key (such as arises with a `default' label) to be
      smaller than anything else.  */
   if (!k1)
diff -ur native/benchspec/CPU/502.gcc_r/src/cpp_symtab.c spec/benchspec/CPU/502.gcc_r/src/cpp_symtab.c
--- native/benchspec/CPU/502.gcc_r/src/cpp_symtab.c	2011-01-19 08:58:21.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/cpp_symtab.c	2021-08-06 08:55:43.102517764 +0530
@@ -169,9 +169,11 @@
       chars[len] = '\0';
       HT_STR (node) = (const unsigned char *) chars;
     }
-  else
+  else {
+		obstack_make_room(&table->stack, 224/*sizeof(tree)*/);
     HT_STR (node) = (const unsigned char *) obstack_copy0 (&table->stack,
 							   str, len);
+	}
 
   if (++table->nelements * 4 >= table->nslots * 3)
     /* Must expand the string table.  */
diff -ur native/benchspec/CPU/502.gcc_r/src/dominance.c spec/benchspec/CPU/502.gcc_r/src/dominance.c
--- native/benchspec/CPU/502.gcc_r/src/dominance.c	2011-01-19 08:58:21.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/dominance.c	2020-10-01 17:06:00.694007751 +0530
@@ -1337,6 +1337,7 @@
 	    continue;
 
 	  dom_i = (size_t) *pointer_map_contains (map, dom);
+		dom_i &= (1ULL << 48) - 1;
 
 	  /* Do not include parallel edges to G.  */
 	  if (bitmap_bit_p ((bitmap) g->vertices[dom_i].data, i))
diff -ur native/benchspec/CPU/502.gcc_r/src/ggc-page.c spec/benchspec/CPU/502.gcc_r/src/ggc-page.c
--- native/benchspec/CPU/502.gcc_r/src/ggc-page.c	2016-06-09 02:46:42.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/ggc-page.c	2020-07-16 20:17:39.477742280 +0530
@@ -569,6 +569,7 @@
 #else
   page_table table = G.lookup;
   size_t high_bits = (size_t) p & ~ (size_t) 0xffffffff;
+	high_bits = high_bits & 0xffffffffffffULL;
   while (1)
     {
       if (table == NULL)
@@ -601,6 +602,7 @@
 #else
   page_table table = G.lookup;
   size_t high_bits = (size_t) p & ~ (size_t) 0xffffffff;
+	high_bits = high_bits & 0xffffffffffffULL;
   while (table->high_bits != high_bits)
     table = table->next;
   base = &table->table[0];
@@ -626,6 +628,7 @@
 #else
   page_table table;
   size_t high_bits = (size_t) p & ~ (size_t) 0xffffffff;
+	high_bits = high_bits & 0xffffffffffffULL;
   for (table = G.lookup; table; table = table->next)
     if (table->high_bits == high_bits)
       goto found;
diff -ur native/benchspec/CPU/502.gcc_r/src/gimple.c spec/benchspec/CPU/502.gcc_r/src/gimple.c
--- native/benchspec/CPU/502.gcc_r/src/gimple.c	2015-10-17 01:58:29.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/gimple.c	2021-08-06 08:55:43.106517779 +0530
@@ -145,6 +145,9 @@
   }
 #endif
 
+	if (size < sizeof(*stmt)) {
+		size = sizeof(*stmt);
+	}
   stmt = (gimple) ggc_alloc_cleared_stat (size PASS_MEM_STAT);
   gimple_set_code (stmt, code);
   gimple_set_num_ops (stmt, num_ops);
diff -ur native/benchspec/CPU/502.gcc_r/src/pointer-set.c spec/benchspec/CPU/502.gcc_r/src/pointer-set.c
--- native/benchspec/CPU/502.gcc_r/src/pointer-set.c	2011-01-19 08:58:21.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/pointer-set.c	2020-10-01 17:06:09.830038312 +0530
@@ -52,7 +52,7 @@
    product, and unsigned arithmetic in C is modulo the word size.  */
 
 static inline size_t
-hash1 (const void *p, unsigned long max, unsigned long logmax)
+hash1 (const void *_p, unsigned long max, unsigned long logmax)
 {
 #if HOST_BITS_PER_LONG == 32
   const unsigned long A = 0x9e3779b9u;
@@ -63,6 +63,8 @@
     = (ULONG_MAX + 1.0L) * 0.6180339887498948482045868343656381177203L;
 #endif
   const unsigned long shift = HOST_BITS_PER_LONG - logmax;
+	unsigned long p = (unsigned long)_p;
+	p &= ((1ULL<<48) - 1);
 
   return ((A * (unsigned long) p) >> shift) & (max - 1);
 }
diff -ur native/benchspec/CPU/502.gcc_r/src/reload1.c spec/benchspec/CPU/502.gcc_r/src/reload1.c
--- native/benchspec/CPU/502.gcc_r/src/reload1.c	2015-10-17 01:58:29.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/reload1.c	2021-08-06 08:55:43.106517779 +0530
@@ -912,7 +912,11 @@
      stack slots to the pseudos that lack hard regs or equivalents.
      Do not touch virtual registers.  */
 
-  temp_pseudo_reg_arr = XNEWVEC (int, max_regno - LAST_VIRTUAL_REGISTER - 1);
+	int _num = max_regno - LAST_VIRTUAL_REGISTER - 1;
+	if (_num == 0) {
+		_num = 1;
+	}
+  temp_pseudo_reg_arr = XNEWVEC (int, _num);
   for (n = 0, i = LAST_VIRTUAL_REGISTER + 1; i < max_regno; i++)
     temp_pseudo_reg_arr[n++] = i;
 
@@ -1865,7 +1869,7 @@
 {
   int freq = REG_FREQ (reg);
   int r = reg_renumber[reg];
-  int nregs = hard_regno_nregs[r][PSEUDO_REGNO_MODE (reg)];
+  int nregs = (r < 0) ? 0 : hard_regno_nregs[r][PSEUDO_REGNO_MODE (reg)];
 
   /* Ignore spilled pseudo-registers which can be here only if IRA is
      used.  */
diff -ur native/benchspec/CPU/502.gcc_r/src/rtl.c spec/benchspec/CPU/502.gcc_r/src/rtl.c
--- native/benchspec/CPU/502.gcc_r/src/rtl.c	2011-01-19 08:58:21.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/rtl.c	2021-08-06 08:55:43.106517779 +0530
@@ -196,7 +196,11 @@
 {
   rtx rt;
 
-  rt = (rtx) ggc_alloc_zone_pass_stat (RTX_CODE_SIZE (code), &rtl_zone);
+	size_t sz = RTX_CODE_SIZE (code);
+	if (sz < sizeof(*rt)) {
+		sz = sizeof(*rt);
+	}
+  rt = (rtx) ggc_alloc_zone_pass_stat (sz, &rtl_zone);
 
   /* We want to clear everything up to the FLD array.  Normally, this
      is one int, but we don't want to assume that and it isn't very
@@ -337,7 +341,10 @@
 rtx
 shallow_copy_rtx_stat (const_rtx orig MEM_STAT_DECL)
 {
-  const unsigned int size = rtx_size (orig);
+  unsigned int size = rtx_size (orig);
+	if (size < sizeof(struct rtx_def)) {
+		size = sizeof(struct rtx_def);
+	}
   rtx const copy = (rtx) ggc_alloc_zone_pass_stat (size, &rtl_zone);
   return (rtx) memcpy (copy, orig, size);
 }
diff -ur native/benchspec/CPU/502.gcc_r/src/sbitmap.c spec/benchspec/CPU/502.gcc_r/src/sbitmap.c
--- native/benchspec/CPU/502.gcc_r/src/sbitmap.c	2014-07-15 20:38:50.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/sbitmap.c	2021-08-06 08:55:43.106517779 +0530
@@ -79,6 +79,9 @@
   bytes = size * sizeof (SBITMAP_ELT_TYPE);
   amt = (sizeof (struct simple_bitmap_def)
 	 + bytes - sizeof (SBITMAP_ELT_TYPE));
+	if (amt < sizeof(*bmap)) {
+		amt = sizeof(*bmap);
+	}
   bmap = (sbitmap) xmalloc (amt);
   bmap->n_bits = n_elms;
   bmap->size = size;
diff -ur native/benchspec/CPU/502.gcc_r/src/sparseset.c spec/benchspec/CPU/502.gcc_r/src/sparseset.c
--- native/benchspec/CPU/502.gcc_r/src/sparseset.c	2011-01-19 08:58:21.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/sparseset.c	2021-08-06 08:55:43.106517779 +0530
@@ -30,6 +30,10 @@
   unsigned int n_bytes = sizeof (struct sparseset_def)
 			 + ((n_elms - 1) * 2 * sizeof (SPARSESET_ELT_TYPE));
 
+	if (n_bytes < sizeof(struct sparseset_def)) {
+		n_bytes = sizeof(struct sparseset_def);
+	}
+
   /* We use xcalloc rather than xmalloc to silence some valgrind uninitialized
      read errors when accessing set->sparse[n] when "n" is not, and never has
      been, in the set.  These uninitialized reads are expected, by design and
diff -ur native/benchspec/CPU/502.gcc_r/src/toplev.c spec/benchspec/CPU/502.gcc_r/src/toplev.c
--- native/benchspec/CPU/502.gcc_r/src/toplev.c	2014-07-15 20:38:50.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/toplev.c	2021-08-04 22:02:05.359337602 +0530
@@ -1700,7 +1700,7 @@
 
   /* Trap fatal signals, e.g. SIGSEGV, and convert them to ICE messages.  */
 #ifdef SIGSEGV
-  signal (SIGSEGV, crash_signal);
+  //signal (SIGSEGV, crash_signal);
 #endif
 #ifdef SIGILL
   signal (SIGILL, crash_signal);
diff -ur native/benchspec/CPU/502.gcc_r/src/tree.c spec/benchspec/CPU/502.gcc_r/src/tree.c
--- native/benchspec/CPU/502.gcc_r/src/tree.c	2015-10-17 01:58:29.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/tree.c	2021-08-06 08:55:43.110517793 +0530
@@ -786,6 +786,9 @@
   tree t;
   enum tree_code_class type = TREE_CODE_CLASS (code);
   size_t length = tree_code_size (code);
+	if (length < sizeof(*t)) {
+		length = sizeof(*t);
+	}
 #ifdef GATHER_STATISTICS
   tree_node_kind kind;
 
@@ -955,6 +958,9 @@
   gcc_assert (code != STATEMENT_LIST);
 
   length = tree_size (node);
+	if (length < sizeof(*t)) {
+		length = sizeof(*t);
+	}
   t = (tree) ggc_alloc_zone_pass_stat (length, &tree_zone);
   memcpy (t, node, length);
 
@@ -1464,6 +1470,9 @@
   tree_node_sizes[(int) c_kind] += length;
 #endif
 
+	if (length < sizeof(*s)) {
+		length = sizeof(*s);
+	}
   s = ggc_alloc_tree (length);
 
   memset (s, 0, sizeof (struct tree_common));
@@ -1581,6 +1590,10 @@
   tree_node_sizes[(int) vec_kind] += length;
 #endif
 
+	if (length < sizeof(*t)) {
+		length += sizeof(*t);
+	}
+
   t = (tree) ggc_alloc_zone_pass_stat (length, &tree_zone);
 
   memset (t, 0, length);
@@ -2099,7 +2112,7 @@
 {
   tree node;
 
-  node = (tree) ggc_alloc_zone_pass_stat (sizeof (struct tree_list), &tree_zone);
+  node = (tree) ggc_alloc_zone_pass_stat (sizeof (*node), &tree_zone);
 
   memset (node, 0, sizeof (struct tree_common));
 
@@ -3601,6 +3614,10 @@
 
   gcc_assert (TREE_CODE_LENGTH (code) == 1);
 
+	if (length < sizeof(*t)) {
+		length = sizeof(*t);
+	}
+
   t = (tree) ggc_alloc_zone_pass_stat (length, &tree_zone);
 
   memset (t, 0, sizeof (struct tree_common));
@@ -9408,6 +9425,9 @@
   tree_node_sizes[(int) e_kind] += length;
 #endif
 
+	if (length < sizeof(*t)) {
+		length = sizeof(*t);
+	}
   t = (tree) ggc_alloc_zone_pass_stat (length, &tree_zone);
 
   memset (t, 0, length);
diff -ur native/benchspec/CPU/502.gcc_r/src/tree-ssa-operands.c spec/benchspec/CPU/502.gcc_r/src/tree-ssa-operands.c
--- native/benchspec/CPU/502.gcc_r/src/tree-ssa-operands.c	2011-01-19 08:58:21.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/tree-ssa-operands.c	2021-08-06 08:55:43.110517793 +0530
@@ -126,11 +126,15 @@
    clobbering sites like function calls or ASM_EXPRs.  */
 #define opf_implicit	(1 << 2)
 
+typedef tree* tree_p;
+DEF_VEC_P(tree_p);
+DEF_VEC_ALLOC_P(tree_p,heap);
+
 /* Array for building all the def operands.  */
-static VEC(tree,heap) *build_defs;
+static VEC(tree_p,heap) *build_defs;
 
 /* Array for building all the use operands.  */
-static VEC(tree,heap) *build_uses;
+static VEC(tree_p,heap) *build_uses;
 
 /* The built VDEF operand.  */
 static tree build_vdef;
@@ -221,8 +225,8 @@
 {
   if (!n_initialized++)
     {
-      build_defs = VEC_alloc (tree, heap, 5);
-      build_uses = VEC_alloc (tree, heap, 10);
+      build_defs = VEC_alloc (tree_p, heap, 5);
+      build_uses = VEC_alloc (tree_p, heap, 10);
       build_vuse = NULL_TREE;
       build_vdef = NULL_TREE;
       bitmap_obstack_initialize (&operands_bitmap_obstack);
@@ -247,8 +251,8 @@
 
   if (!--n_initialized)
     {
-      VEC_free (tree, heap, build_defs);
-      VEC_free (tree, heap, build_uses);
+      VEC_free (tree_p, heap, build_defs);
+      VEC_free (tree_p, heap, build_uses);
       build_vdef = NULL_TREE;
       build_vuse = NULL_TREE;
     }
@@ -413,7 +417,7 @@
   unsigned new_i;
   struct def_optype_d new_list;
   def_optype_p old_ops, last;
-  unsigned int num = VEC_length (tree, build_defs);
+  unsigned int num = VEC_length (tree_p, build_defs);
 
   /* There should only be a single real definition per assignment.  */
   gcc_assert ((stmt && gimple_code (stmt) != GIMPLE_ASSIGN) || num <= 1);
@@ -427,7 +431,7 @@
 	oldvdef = SSA_NAME_VAR (oldvdef);
       if (oldvdef != build_vdef)
 	gimple_set_vdef (stmt, build_vdef);
-      VEC_safe_insert (tree, heap, build_defs, 0, (tree)gimple_vdef_ptr (stmt));
+      VEC_safe_insert (tree_p, heap, build_defs, 0, (tree_p)gimple_vdef_ptr (stmt));
       ++num;
     }
 
@@ -457,7 +461,7 @@
 
   /* Check for the common case of 1 def that hasn't changed.  */
   if (old_ops && old_ops->next == NULL && num == 1
-      && (tree *) VEC_index (tree, build_defs, 0) == DEF_OP_PTR (old_ops))
+      && (tree *) VEC_index (tree_p, build_defs, 0) == DEF_OP_PTR (old_ops))
     return;
 
   /* If there is anything in the old list, free it.  */
@@ -469,7 +473,7 @@
 
   /* If there is anything remaining in the build_defs list, simply emit it.  */
   for ( ; new_i < num; new_i++)
-    last = add_def_op ((tree *) VEC_index (tree, build_defs, new_i), last);
+    last = add_def_op ((tree *) VEC_index (tree_p, build_defs, new_i), last);
 
   /* Now set the stmt's operands.  */
   gimple_set_def_ops (stmt, new_list.next);
@@ -496,7 +500,7 @@
       if (oldvuse != (build_vuse != NULL_TREE
 		      ? build_vuse : build_vdef))
 	gimple_set_vuse (stmt, NULL_TREE);
-      VEC_safe_insert (tree, heap, build_uses, 0, (tree)gimple_vuse_ptr (stmt));
+      VEC_safe_insert (tree_p, heap, build_uses, 0, (tree_p)gimple_vuse_ptr (stmt));
     }
 
   new_list.next = NULL;
@@ -528,9 +532,9 @@
     }
 
   /* Now create nodes for all the new nodes.  */
-  for (new_i = 0; new_i < VEC_length (tree, build_uses); new_i++)
+  for (new_i = 0; new_i < VEC_length (tree_p, build_uses); new_i++)
     last = add_use_op (stmt,
-		       (tree *) VEC_index (tree, build_uses, new_i),
+		       (tree *) VEC_index (tree_p, build_uses, new_i),
 		       last);
 
   /* Now set the stmt's operands.  */
@@ -546,8 +550,8 @@
 {
   build_vdef = NULL_TREE;
   build_vuse = NULL_TREE;
-  VEC_truncate (tree, build_defs, 0);
-  VEC_truncate (tree, build_uses, 0);
+  VEC_truncate (tree_p, build_defs, 0);
+  VEC_truncate (tree_p, build_uses, 0);
 }
 
 
@@ -567,8 +571,8 @@
 static inline void
 start_ssa_stmt_operands (void)
 {
-  gcc_assert (VEC_length (tree, build_defs) == 0);
-  gcc_assert (VEC_length (tree, build_uses) == 0);
+  gcc_assert (VEC_length (tree_p, build_defs) == 0);
+  gcc_assert (VEC_length (tree_p, build_uses) == 0);
   gcc_assert (build_vuse == NULL_TREE);
   gcc_assert (build_vdef == NULL_TREE);
 }
@@ -579,7 +583,7 @@
 static inline void
 append_def (tree *def_p)
 {
-  VEC_safe_push (tree, heap, build_defs, (tree) def_p);
+  VEC_safe_push (tree_p, heap, build_defs, (tree_p) def_p);
 }
 
 
@@ -588,7 +592,7 @@
 static inline void
 append_use (tree *use_p)
 {
-  VEC_safe_push (tree, heap, build_uses, (tree) use_p);
+  VEC_safe_push (tree_p, heap, build_uses, (tree_p) use_p);
 }
 
 
diff -ur native/benchspec/CPU/502.gcc_r/src/tree-ssa-sccvn.c spec/benchspec/CPU/502.gcc_r/src/tree-ssa-sccvn.c
--- native/benchspec/CPU/502.gcc_r/src/tree-ssa-sccvn.c	2015-10-01 21:08:20.000000000 +0530
+++ spec/benchspec/CPU/502.gcc_r/src/tree-ssa-sccvn.c	2021-08-06 08:55:43.110517793 +0530
@@ -1539,6 +1539,8 @@
   void **slot;
   vn_nary_op_t vno1;
 
+	obstack_make_room(&current_info->nary_obstack, sizeof(*vno1));
+
   vno1 = (vn_nary_op_t) obstack_alloc (&current_info->nary_obstack,
 				       (sizeof (struct vn_nary_op_s)
 					- sizeof (tree) * (4 - length)));
@@ -1577,6 +1579,7 @@
   vn_nary_op_t vno1;
   unsigned i;
 
+	obstack_make_room(&current_info->nary_obstack, sizeof(*vno1));
   vno1 = (vn_nary_op_t) obstack_alloc (&current_info->nary_obstack,
 			(sizeof (struct vn_nary_op_s)
 			 - sizeof (tree) * (4 - length)));
@@ -1607,6 +1610,8 @@
   vn_nary_op_t vno1;
   unsigned i;
 
+	obstack_make_room(&current_info->nary_obstack, sizeof(*vno1));
+
   vno1 = (vn_nary_op_t) obstack_alloc (&current_info->nary_obstack,
 				       (sizeof (struct vn_nary_op_s)
 					- sizeof (tree) * (4 - length)));
